{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and Export\n",
    "\n",
    "This notebook fetches and processes data from a specified database and exports it to a CSV file. The data includes item information and sales prices, which are then filtered and merged based on specific conditions. Finally, the processed data is exported to a CSV file with a unique filename based on the current timestamp. The process is scheduled to run daily at 15:02.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we import the necessary libraries for data processing and database connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pyodbc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "We establish a connection to the NCT2-RBO database using the specified server, database name, username, and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'your_server_name' \n",
    "database = 'your_database_name' \n",
    "username = 'your_username' \n",
    "password = 'your_password'  \n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+password)\n",
    "cursor = cnxn.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data\n",
    "We execute SQL queries to fetch data from the Item and SalesPrice tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_item = \"SELECT * FROM [Item];\"\n",
    "df_item = pd.read_sql(query_item, cnxn)\n",
    "\n",
    "query_sales = \"SELECT * FROM [SalesPrice];\"\n",
    "df_sales = pd.read_sql(query_sales, cnxn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We convert the Starting Date and Ending Date columns to datetime format, filter the DataFrame based on date range, and merge the filtered sales data with item data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Convert 'Starting Date' and 'Ending Date' to datetime format\n",
    "df_sales['Starting Date'] = pd.to_datetime(df_sales['Starting Date'], errors='coerce').dt.date\n",
    "df_sales['Ending Date'] = pd.to_datetime(df_sales['Ending Date'], errors='coerce')\n",
    "\n",
    "    # Define date range for filtering\n",
    "date_from = pd.to_datetime('2022-01-01').date()\n",
    "date_to = pd.to_datetime('1753-01-01 00:00:00.000')\n",
    "\n",
    "    # Filter the DataFrame based on date range\n",
    "filtered_df = df_sales[(df_sales['Starting Date'] < date_from) & (df_sales['Ending Date'] == date_to)]\n",
    "\n",
    "    # Select specific columns from the filtered DataFrame\n",
    "filtered_df = filtered_df[['ItemNo', 'Starting Date', 'Ending Date', 'SalesCode']]\n",
    "\n",
    "    # Select specific columns from the item DataFrame\n",
    "state = df_item[['No', 'ProductStatus', 'DivisionCode']]\n",
    "\n",
    "# Merge the two DataFrames based on 'ItemNo' and 'No'\n",
    "merged_df_with_status = pd.merge(filtered_df, state, left_on='ItemNo', right_on='No', how='left')\n",
    "\n",
    " # Select specific columns from the merged DataFrame\n",
    "merged_df_with_status_filtered = merged_df_with_status[['ItemNo', 'SalesCode', 'DivisionCode', 'Starting Date', 'Ending Date', 'ProductStatus']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Codes with Descriptions\n",
    "We replace numerical product status codes and division codes with their corresponding descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Replace numerical product status codes with their corresponding status descriptions\n",
    "replace_values = {\n",
    "        0: 'NO status', 1: 'New', 2: 'Live', 3: 'Delete', 4: 'Clean',\n",
    "        5: 'Block', 6: 'Block Consumer', 7: 'Block BOM', 8: 'Transfer & Purchase',\n",
    "        9: 'All-Exp-SA', 10: 'Purchase Block', 11: 'Multi-Location'\n",
    "    }\n",
    "merged_df_with_status_filtered = merged_df_with_status_filtered.replace({\"ProductStatus\": replace_values})\n",
    "\n",
    "    # Replace numerical division codes with their corresponding division descriptions\n",
    "replace_values_Division = {\n",
    "        1: 'FMCG', 2: 'Fresh Food', 3: 'General Merchandising', 4: 'Tenants',\n",
    "        5: 'Overhead', 12: 'Penalty', 99: 'ETax'\n",
    "    }\n",
    "merged_df_with_status_filtered = merged_df_with_status_filtered.replace({\"DivisionCode\": replace_values_Division})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization : Distribution of Product Statuses\n",
    "Generate a bar plot showing the distribution of product statuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=merged_df_with_status_filtered, x='ProductStatus', order=merged_df_with_status_filtered['ProductStatus'].value_counts().index)\n",
    "plt.title('Distribution of Product Statuses')\n",
    "plt.xlabel('Product Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization : Distribution of Starting Dates\n",
    "This block generates a histogram showing the distribution of `Starting Date` values in the filtered dataset. It helps in understanding the frequency of item start dates before the specified date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Visualization 1: Distribution of Starting Dates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_df['Starting Date'], bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of Starting Dates')\n",
    "plt.xlabel('Starting Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization : Heatmap of Product Status by Division\n",
    "Generate a heatmap showing the relationship between product status and division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "status_by_division = merged_df_with_status_filtered.pivot_table(index='DivisionCode', columns='ProductStatus', aggfunc='size', fill_value=0)\n",
    "sns.heatmap(status_by_division, annot=True, fmt='d', cmap='viridis')\n",
    "plt.title('Heatmap of Product Status by Division')\n",
    "plt.xlabel('Product Status')\n",
    "plt.ylabel('Division Code')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data to CSV\n",
    "We export the final processed DataFrame to a CSV file with a unique filename based on the current timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "filename = f'./NO_EndDate_status_{now_str}.csv'\n",
    "merged_df_with_status_filtered.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule the Task\n",
    "We schedule the process_data function to run daily at 15:02 and keep the script running to execute the scheduled task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every().day.at(\"15:02\").do(process_data)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
